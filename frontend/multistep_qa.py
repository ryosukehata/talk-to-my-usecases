import logging
import sys
import asyncio

import streamlit as st
from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam
from openai.types.chat.chat_completion_user_message_param import (
    ChatCompletionUserMessageParam,
)
from openai.types.chat.chat_completion_assistant_message_param import (
    ChatCompletionAssistantMessageParam,
)


from helpers import clear_data_callback, state_init,get_telemetry_data
from streamlit_utils import (
    handle_first_question,
    _handle_questions_response,
    _handle_solution_response,
    handle_user_answers_form,
    handle_ai_response,
)

sys.path.append("..")

from utils.api import (
    fetch_dx_tool_suggestions,
    process_uploaded_file,
)
from utils.schema import PromptType
# --- OpenAI APIã®è¨­å®š ---


logger = logging.getLogger("TalkToMyUseCase")
MAX_QUESTION_ROUNDS = 5



# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---
st.set_page_config(page_title="DXãƒ†ãƒ¼ãƒå®šç¾©æ”¯æ´ã‚¢ãƒ—ãƒª", layout="wide")

async def main():
    """
    ãƒ¡ã‚¤ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    st.title("DXãƒ†ãƒ¼ãƒå®šç¾©æ”¯æ´ã‚¢ãƒ—ãƒª ğŸ’¡")
    st.caption("ãµã‚ã£ã¨ã—ãŸã€Œã‚„ã‚ŠãŸã„ã“ã¨ã€ã‹ã‚‰ã€DXã®ãƒ†ãƒ¼ãƒã¨ToDoã‚’å…·ä½“åŒ–ã—ã¾ã™ã€‚(OpenAI APIé€£æºç‰ˆ)")
    await state_init()

    # --- ã‚¹ãƒ†ãƒƒãƒ—1: ã‚„ã‚ŠãŸã„ã“ã¨ã®å…¥åŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
    st.header("ã€Œã‚„ã‚ŠãŸã„ã“ã¨ã€ã‚’æ•™ãˆã¦ãã ã•ã„")
    initial_user_request = st.text_area(
        "ä¾‹: å–¶æ¥­éƒ¨é–€ã®å ±å‘Šæ›¸ä½œæˆæ¥­å‹™ã‚’åŠ¹ç‡åŒ–ã—ãŸã„ã€é¡§å®¢ã®è§£ç´„ç‡ã‚’äºˆæ¸¬ã—ãŸã„ã€æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ãŸãã•ã‚“å‡ºã—ãŸã„...",
        key="initial_request_input_openai",
        height=100,
        value=st.session_state.user_request_buffer
        )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    st.subheader("å‚è€ƒè³‡æ–™ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    st.caption("ç¾çŠ¶ã®æ¥­å‹™ã‚„ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

    with st.expander("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹", expanded=True):
        uploaded_file = st.file_uploader(
            "Excelã€CSVã€PowerPointã€Wordæ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™",
            type=["xlsx", "xls", "csv", "pptx", "docx"],
            key=st.session_state.file_uploader_key,
        )

        if uploaded_file:
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            with st.spinner(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{uploaded_file.name}ã€ã‚’å‡¦ç†ä¸­..."):
                file_info = process_uploaded_file(uploaded_file)
                st.session_state.uploaded_files[uploaded_file.name] = file_info
                st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{uploaded_file.name}ã€ãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")
                st.info(file_info["summary"])

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        if st.session_state.uploaded_files:
            st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«:")
            for filename, file_info in st.session_state.uploaded_files.items():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"ğŸ“„ {filename}")
                    st.caption(file_info["summary"])
                with col2:
                    if st.button("å‰Šé™¤", key=f"delete_{filename}"):
                        del st.session_state.uploaded_files[filename]
                        st.rerun()

    # é€ä¿¡ãƒœã‚¿ãƒ³
    if st.button("AIã«ç›¸è«‡ã™ã‚‹", 
                 key="submit_initial_request_openai"):
        if initial_user_request:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ ã—ãŸå†…å®¹ã‚’ä½œæˆ
            file_context = ""
            if st.session_state.uploaded_files:
                file_context = "\n\nã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:\n"
                for filename, file_info in st.session_state.uploaded_files.items():
                    file_context += f"- {filename}: {file_info['summary']}\n"

            combined_input = initial_user_request + file_context

            st.session_state.user_request = combined_input
            st.session_state.user_request_ = initial_user_request  # å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã ã‘ã‚’ä¿æŒ
            st.session_state.telemetry_json = await get_telemetry_data()
            print(st.session_state.telemetry_json)
            
            await handle_first_question(combined_input)
            st.rerun()
        else:
            st.warning("ã€Œã‚„ã‚ŠãŸã„ã“ã¨ã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # --- AIã«ã‚ˆã‚‹åˆ†æã¨å¿œç­”å‡¦ç† ---
    if st.session_state.conversation_stage == PromptType.DECISION:
        with st.spinner("AIãŒåˆ†æä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
            # chat_history ã«ã¯æ—¢ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®å…¥åŠ›ãŒå«ã¾ã‚Œã¦ã„ã‚‹
            print(st.session_state.chat_history)
            print(st.session_state.conversation_stage)
            ai_response = await fetch_dx_tool_suggestions(st.session_state.chat_history,
                                                          st.session_state.use_tools_and_descriptions,
                                                          telemetry_json=st.session_state.telemetry_json,
                                                          prompt_type=st.session_state.conversation_stage,
                                                          result_validation=False)
            # AIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†
            response_type = await handle_ai_response(ai_response)
            print("Decision result is "+str(response_type))
            st.session_state.conversation_stage = response_type

    # --- AIã‹ã‚‰ã®è¿½åŠ è³ªå•ä½œæˆ ---
    if st.session_state.conversation_stage == PromptType.QUESTION and st.session_state.question_counter <= MAX_QUESTION_ROUNDS:
        # æ®‹ã‚Šã®è³ªå•å›æ•°ã‚’è¡¨ç¤º

        ai_response = await fetch_dx_tool_suggestions(st.session_state.chat_history,
                                                      st.session_state.use_tools_and_descriptions,
                                                      telemetry_json=st.session_state.telemetry_json,
                                                      prompt_type=st.session_state.conversation_stage,
                                                      result_validation=False)
        st.info(f"AIã«ã‚ˆã‚‹è³ªå•å›æ•°: {st.session_state.question_counter}å› / æœ€å¤§5å›ä¸­")
        _handle_questions_response(ai_response)


    # -- AIã‹ã‚‰ã®è³ªå•ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’å¾…ã¤ --
    if st.session_state.conversation_stage == "AWAITING_ANSWERS":
        # AIã®è³ªå•ã‚’ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.info(st.session_state.chat_history[-1-len(st.session_state.ai_questions)]["content"])

        with st.form(key="answers_form_genai"):
            await handle_user_answers_form()


    # --- DXãƒ„ãƒ¼ãƒ«ã¨ToDoãƒªã‚¹ãƒˆã®ç”Ÿæˆ ---
    if st.session_state.conversation_stage == PromptType.SOLUTION or st.session_state.question_counter > MAX_QUESTION_ROUNDS:
        ai_response = await fetch_dx_tool_suggestions(st.session_state.chat_history,
                                                      st.session_state.use_tools_and_descriptions,
                                                      telemetry_json=st.session_state.telemetry_json,
                                                      prompt_type=st.session_state.conversation_stage,
                                                      result_validation=False)
        _handle_solution_response(ai_response)
                                                
    # --- DXãƒ„ãƒ¼ãƒ«ã¨ToDoãƒªã‚¹ãƒˆã®è¡¨ç¤º ---
    if st.session_state.conversation_stage == "SHOWING_SOLUTION" and st.session_state.dx_solution:
        solution = st.session_state.dx_solution
    
        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if "tools" in solution and solution["tools"] and solution["tools"][0] != "ã‚¨ãƒ©ãƒ¼":
            st.success("DXãƒ†ãƒ¼ãƒã®å®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            st.error("DXãƒ†ãƒ¼ãƒã®å®šç¾©ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        # ææ¡ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.markdown(f"*{solution.get('message', '')}*")
    
        # ä¸»è¦ãªDXãƒ„ãƒ¼ãƒ«ã®è¡¨ç¤º
        primary_tool = solution.get('primary_tool', solution.get('tools', ['N/A'])[0] if solution.get('tools') else 'N/A')
        st.subheader(f"ææ¡ˆã™ã‚‹ä¸»è¦DXãƒ„ãƒ¼ãƒ«: **{primary_tool}**")
    
        # è¤‡æ•°ã®DXãƒ„ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹å ´åˆ
        if 'tool_combinations' in solution and solution['tool_combinations']:
            st.subheader("DXãƒ„ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›:")
        
            for i, tool_combo in enumerate(solution['tool_combinations']):
                with st.expander(f"{i+1}. {tool_combo.get('tool', 'N/A')} - {tool_combo.get('purpose', '')}"):
                    st.markdown(f"**å½¹å‰²**: {tool_combo.get('purpose', 'N/A')}")
                    st.markdown("**é–¢é€£ã™ã‚‹ToDoãƒªã‚¹ãƒˆ**:")
                    tool_todos = tool_combo.get('todos', [])
                    if tool_todos:
                        for j, todo_text in enumerate(tool_todos):
                            st.checkbox(f"{todo_text}", key=f"todo_combo_{i}_{j}")
                    else:
                        st.write("ã“ã®ãƒ„ãƒ¼ãƒ«ã«é–¢é€£ã™ã‚‹ToDoãƒªã‚¹ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    
        # å…¨ä½“çš„ãªToDoãƒªã‚¹ãƒˆã®è¡¨ç¤º
        st.subheader("å…¨ä½“çš„ãªæ¨å¥¨ToDoãƒªã‚¹ãƒˆ:")
        todos = solution.get('todos', [])
        if todos:
            for i, todo_text in enumerate(todos):
                st.checkbox(f"{todo_text}", key=f"todo_overall_{i}")
        else:
            st.write("ToDoãƒªã‚¹ãƒˆã¯æä¾›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        # ä½¿ç”¨ã•ã‚Œã‚‹DXãƒ„ãƒ¼ãƒ«ä¸€è¦§ã®è¡¨ç¤º
        if 'tools' in solution and len(solution['tools']) > 1:
            st.subheader("ä½¿ç”¨ã™ã‚‹DXãƒ„ãƒ¼ãƒ«ã®ä¸€è¦§:")
            tool_list_html = ""
            for tool in solution['tools']:
                if tool == primary_tool:
                    tool_list_html += f"- **{tool}** (ä¸»è¦ãƒ„ãƒ¼ãƒ«)\n"
                else:
                    tool_list_html += f"- {tool}\n"
            st.markdown(tool_list_html)

        st.markdown("---")

        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ã‚‚ã†ä¸€åº¦ã€æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™", 
                     key="restart_process_openai",
                     on_click=clear_data_callback):
            st.rerun()


    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º (ã‚µã‚¤ãƒ‰ãƒãƒ¼) ---
    if st.sidebar.checkbox("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹", key="show_chat_history_openai", value=True):
        st.sidebar.subheader("ä¼šè©±ã®å±¥æ­´")
        if not st.session_state.get('chat_history', []):
            st.sidebar.write("ã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        for entry in st.session_state.get('chat_history', []):
            with st.sidebar.chat_message(entry["role"]):
                st.markdown(entry["content"])

    st.sidebar.markdown("---")
    st.sidebar.header("ã‚¢ãƒ—ãƒªæ§‹æƒ³ã«ã¤ã„ã¦")
    st.sidebar.markdown("""
    ã“ã®ã‚¢ãƒ—ãƒªã¯AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’åˆ©ç”¨ã—ã¦AIã¨ã®å¯¾è©±ã‚’è¡Œãªã£ã¦ã„ã¾ã™ã€‚
    å®Ÿç¾ã—ãŸã„ã“ã¨ã«å¯¾ã—ã¦DXã®ã©ã‚“ãªæŠ€è¡“ã§è§£æ±ºã§ããã†ã‹åˆ¤æ–­ã—ã¦ãã‚Œã¾ã™ã€‚
    """)


asyncio.run(main())
