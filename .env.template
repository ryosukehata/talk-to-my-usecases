# Refer to https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#create-a-datarobot-api-key
# and https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#retrieve-the-api-endpoint
# Can be deleted on a DataRobot codespace
DATAROBOT_API_TOKEN=
DATAROBOT_ENDPOINT=

# Required, unless logged in to pulumi cloud. Choose your own alphanumeric passphrase to be used for encrypting pulumi config
PULUMI_CONFIG_PASSPHRASE=123

# Optional: Choose which frontend implementation to use (streamlit or react)
# FRONTEND_TYPE=streamlit

# To use an existing TextGen Model or Deployment:
#  1. Provide either the registered model ID, or the deployment ID 
#  2. Set CHAT_MODEL_NAME to the model name expected by the TextGen model (e.g. gpt-4o-mini)
#  3. Set LLM=DEPLOYED_LLM in infra/settings_generative.py

# TEXTGEN_REGISTERED_MODEL_ID=
# TEXTGEN_DEPLOYMENT_ID=
# CHAT_MODEL_NAME=datarobot-deployed-llm # for NIM models, "datarobot-deployed-llm" will automatically be translated to the correct model name.

# For Azure OpenAI: 

# Refer to (https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython-new&pivots=programming-language-python#retrieve-key-and-endpoint)

# OPENAI_API_KEY=
# OPENAI_API_BASE=
# OPENAI_API_VERSION=
# OPENAI_API_DEPLOYMENT_ID=

# For Snowflake (Optional)
# Either password authentication:
# SNOWFLAKE_USER=
# SNOWFLAKE_PASSWORD=
# Or key file authentication:
# SNOWFLAKE_KEY_PATH=

# Common Snowflake settings (required if using Snowflake):
# SNOWFLAKE_ACCOUNT=
# SNOWFLAKE_WAREHOUSE=
# SNOWFLAKE_DATABASE=
# SNOWFLAKE_SCHEMA=
# SNOWFLAKE_ROLE=

# For Google VertexAI

# You will need a service account JSON with aiplatform.endpoints.predict permission (https://cloud.google.com/iam/docs/keys-create-delete)
# GOOGLE_DB_SCHEMA is required if using BigQuery as a database but can be omitted for Vertex LLMs
# Add the JSON file content enclosed by '' here:

# GOOGLE_SERVICE_ACCOUNT=
# GOOGLE_REGION=
# GOOGLE_DB_SCHEMA=

# For AWS Bedrock:

# Refer to https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
# AWS_SESSION_TOKEN is optional in case you are using a long term access key

# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_SESSION_TOKEN=
# AWS_REGION=

# For SAP DataSphere
# SAP_DATASPHERE_HOST=
# SAP_DATASPHERE_PORT=
# SAP_DATASPHERE_USER=
# SAP_DATASPHERE_PASSWORD=
# SAP_DATASPHERE_SCHEMA=
